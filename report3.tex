\documentclass[11pt,a4paper,oneside]{report}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}

\begin{document}
\title{HPSC Assignment 3}
\author{Gregory Petropoulos}
\date{September 26, 2012}
\maketitle

\section{Dense Matrix Transpose}

For this problem we have an nxn matrix $A$ stored on processor 0 and we want to send $A^T$ to processor 1.  In this problem I made the matrix elements integers.  I performed the transpose by using the MPI derived data type MPI\_Type\_Vector.  This derived data type easily allows you to store a column of a matrix by setting the data types length to n and stride to n.  I chose to call this data type `col'.  To send the transpose of the matrix to processor one it is necessary to send the column data type and receive it as a row.  Thus the MPI\_Send will use the derived data type, however the MPI\_Recv will just receive n integers as a row.  Testing this program was simple, I just generated the output shown in Figure(\ref{fig:transpose}) which is correct.

\begin{figure}[htpb]
  \texttt{Processor name:  econ3-52-8-dhcp.int.colorado.edu\\}
  \texttt{A =\\}
  \texttt{0 1 2 \\}
  \texttt{3 4 5 \\}
  \texttt{6 7 8 \\\\}
  \texttt{Processor name:  econ3-52-8-dhcp.int.colorado.edu\\}
  \texttt{Transpose(A) =\\}
  \texttt{0 3 6 \\}
  \texttt{1 4 7 \\}
  \texttt{2 5 8 \\}
  \caption{Output for my dense matrix transpose program.}
  \label{fig:transpose}
\end{figure}

\section{Matrix Multiplication Techniques}

There are two dense matrix multiplication techniques that we have talked about thus far:  Fox's algorithm and using successive MPI\_Allgather.  For this problem we were given source codes and had to modify them.  Modifications that went into the Fox algorithm were to produce the matrices rather than read them in from standard input and take the matrix dimension from the command line.  Modifications that went into the all gather algorithm were to change the program from a matrix vector multiplication to a matrix matrix multiplication and read the matrix dimension from the command line.  Changing the way the multiplication was implemented required n uses of MPI\_Allgather which was the crux of the changes.  For both programs proper timings had to be added as well to asses the performance of the algorithms.

For testing I ran the programs and printed out the matrices generating Figure(\ref{fig:fox}) which shows that my implementation of the Fox algorithm is correct and 
Figure(\ref{fig:allgather}) which demonstrates that my implementation of the all gather algorithm is correct as well.

\begin{figure}[htpb]
  \texttt{We read A =\\}
  \texttt{0.0  1.0  0.0  1.0 \\}
  \texttt{4.0  5.0  4.0  5.0 \\}
  \texttt{0.0  1.0  0.0  1.0 \\}
  \texttt{4.0  5.0  4.0  5.0 \\}
  \texttt{We read B =\\}
  \texttt{0.0  1.0  0.0  1.0 \\}
  \texttt{4.0  5.0  4.0  5.0 \\}
  \texttt{0.0  1.0  0.0  1.0 \\}
  \texttt{4.0  5.0  4.0  5.0 \\}
  \texttt{. . .\\}
  \texttt{The product is\\}
  \texttt{8.0 10.0  8.0 10.0 \\}
  \texttt{40.0 58.0 40.0 58.0 \\}
  \texttt{8.0 10.0  8.0 10.0 \\}
  \texttt{40.0 58.0 40.0 58.0 \\}
  \caption{Output generated by fox.c showing that the multiplication is correct.}
  \label{fig:fox}
\end{figure}

\begin{figure}[htpb]
  \texttt{The matrix A\\}
  \texttt{0.268992 0.581220 \\}
  \texttt{0.840188 0.394383 \\}

  \texttt{The matrix B}
  \texttt{0.089854 0.066885 \\}
  \texttt{0.783099 0.798440 \\}

  \texttt{The matrix C\\}
  \texttt{0.479323 0.482061 \\}
  \texttt{0.384335 0.371087 \\}
  \caption{Output generated by mpi\_mat\_vect\_time.c showing that the multiplication is correct.}
  \label{fig:allgather}
\end{figure}

\pagebreak

For timings there are two tests that we are interested in:
\begin{enumerate}
  \item Matrix size 144x144 tested at:
    \begin{itemize}
      \item parallel allgather: np = 4, 16, 36, 72
      \item Fox’s: np = 4, 16, 36, 64
    \end{itemize}
  \item Matrix sizes 144x144, 576x576, 1152x1152, 2304x2304 tested at:
    \begin{itemize}
      \item parallel allgather: np = 72
      \item Fox’s: np = 64
    \end{itemize}
\end{enumerate}

The first test checks how the algorithms scale with more processors.  The second test checks how the algorithms scale with the problem size.  To produce the timing data I ran on Gordon and executed the matrix multiplication 100 times.  Depending on the run there was need for anywhere between 0 and 2 warm up runs so I threw out the first two timings across the board.

The results from the first test, Figure(\ref{fig:fixedmatrix}), show that as you add more processors the communication overhead for the all gather algorithm kills its performance and causes the time to completion to grow as more processors are added.  In contrast, the Fox algorithm has a very low communication overhead so adding more cores increases performance, decreasing time to completion.  There are a few nuanced details of Figure(\ref{fig:fixedmatrix}).  It appears that both algorithms scale similarly for 4 and 16 cores.  This is because the nodes on Gordon have 16 cores and communication on a single node is very fast.  For more than 16 cores the program has to communicate over the infinibad which is much slower; in this regime the Fox algorithm becomes a factor of 10 faster on 64 cores compared to 4 cores and Allgather becomes a factor of 10 slower on 72 cores compared to 4 cores.

\begin{figure}[htpb]
  \centering
  \includegraphics[width=4in]{Figures/fixedmatrix.png}
  \caption{How the two matrix multiplications scale with increased parallelism.}
  \label{fig:fixedmatrix}
\end{figure}

The results from the second test, Figure(\ref{fig:fixedcores}), show that as you increase the problem size both the Allgather and the Fox algorithm have a slower time to get the result.  The scaling for both algorithms is roughly the same, however for all problem sizes the Fox algorithm is faster than the Allgather algorithm.  For small problem sizes the fox algorithm is much faster while increasing the problem size closes the performance gap between the two algorithms.

\begin{figure}[htpb]
  \centering
  \includegraphics[width=4in]{Figures/fixedcores.png}
  \caption{How the two matrix multiplication techniques scale with increased problem size.}
  \label{fig:fixedcores}
\end{figure}

\end{document}
